---
title: "age_gender_simulation"
output: html_document
date: "2024-09-18"
---


```{r Initialization, message=FALSE, warning=FALSE, include=FALSE}
# rm(list = ls())
if (!require("pacman")) install.packages("pacman")

pacman::p_load("tidyverse", "ggh4x","stringr", "patchwork", "BayesFactor", "gtools", "bruceR")

pacman::p_load("iterators", "foreach","parallel", "doParallel")

pacman::p_load("truncnorm")

options(scipen=999) 
```

# Bayesian multinomial test

## Background



Here, `alphas` defined the prior Dirichlet distribution, e.g., noninformative prior is a vector of $1$s, `counts` are the observed frequencies.

To use the algorithm in R, we defined a function here:

```{r define BF for Multinomial test, message=FALSE, warning=FALSE}
BayesMultiNomial <- function(dataset, factor, observed, expected, default_prior = TRUE, prior = NA){
  # datase - the input dataframe
  # factor - column name of the factor,
  # observed - column name of the column contains counts information for the observed,
  # expected - column name of the column contains counts information for the expected,
  # default_prior - whether use the default, defused prior
  # prior - priors defined by users
  
  fact_level <- dataset %>% dplyr::select(all_of(factor)) %>% dplyr::pull()
  observed_data <- dataset %>% dplyr::select(all_of(observed)) %>% dplyr::pull()
  names(observed_data) <- fact_level
  expected_data <- dataset %>% dplyr::select(all_of(expected)) %>% dplyr::pull()
  n_levels <- length(observed_data)
  
  
  if (default_prior & all(is.na(prior))) {
    prior <- rep(1, n_levels)
  } else{
    if (is.character(prior)){
      prior <- dataset %>% dplyr::select(all_of(prior)) %>% dplyr::pull()
    } else if (is.array(prior)){
      prior <-  prior
    } else if (is.numeric(prior)){
      prior <-  prior
    } else{
      print("prior much a column of the input data or a vector")
    }
  }
  
  alphas <- prior
  counts <- observed_data
  thetas <- expected_data
  
  if(sum(thetas) != 1) {
    thetas <- thetas/sum(thetas)
    }
  
  expected <- setNames(sum(counts)*thetas, names(counts))
  
  lbeta.xa <- sum(lgamma(alphas + counts)) - lgamma(sum(alphas + counts))
  lbeta.a  <- sum(lgamma(alphas)) - lgamma(sum(alphas))

  if (any(rowSums(cbind(thetas, counts)) == 0)) {
    LogBF10 <- (lbeta.xa-lbeta.a)
  } else {
    LogBF10 <- (lbeta.xa-lbeta.a) + (0 - sum(counts * log(thetas))) 
  }

  BF <- data.frame(LogBF10 = LogBF10,
                   BF10    = exp(LogBF10),
                   BF01    = 1/exp(LogBF10))

  return(list(BF       = BF,
              expected = expected))
  
}
```

### Justification for the Bayesian multinomial test


To test whether the current non-informative prior is reasonable, we conducted a simulation to test the sensitivity.

We tested the false positive rate of the current setting and false negative (power = 1 - FN ) of the current setting under different deviation from the expected. 

#### Test the default prior for sex ratio

For sex ratio, we used the $Y \sim Binomial(p = 0.5)$ as the null model, any deviation from $0.5$ will be viewed as different from the null effect. 

**False Positive Rate**: The proportion of $BF_{01}$ that greater than 6.

**Power**: The proportion of $BF_{01}$ that greater than 6.


As the $H_1$ is any deviation from the null, we need to get a reasonable smallest effect size of interest. We used data from [Rad et al., 2018](https://www.pnas.org/content/115/45/11401) for this purpose.

In this paper, Rad et al. surveyed papers published in *Psychological Science* on how the demographic information reported in these papers. In the supplementary, they provided 35 studies, which can be identified and their participants' sex ratio can be found. We used these data as our basis of smallest effect size of interest.

```{r smallest effect size of interest, eval=FALSE}
df_rad2018 <- read.csv("Rad_2018_suppl.csv") %>%
  dplyr::mutate(male_num = as.numeric(male_num),
                female_num = as.numeric(female_num)) %>%
  dplyr::filter(!is.na(male_num)) %>%
  dplyr::select(1:2, 13:14) %>%
  dplyr::mutate(prop = male_num/(male_num + female_num),
                deviation = prop - 0.5,
                dev_abs = abs(deviation)) %>%
  dplyr::arrange(dev_abs)
df_rad2018
effect_size <- bootES::bootES(df_rad2018$dev_abs, plot=TRUE)
effect_size
```

We found that the mean deviation from 0.5, estimated by `bootES`, is 0.085, 95% CI[0.061 0.115]. Following the practices of previous study [Kirby & Gerlanc,2013](https://doi.org/10.3758/s13428-013-0330-5), we decided to used the lower boundary of this CI, 0.06 as the smallest effect size of interest. 

```{r define function for testing sex ratio, message=TRUE, warning=FALSE,eval=FALSE}
# define a function to run the simulation for sex ratio
Sim_Power_binormial <- function(seed = 12345, sim_N = 1000, ss = 1000, effect = 0, nil_effect = 0.5, prior = 1){
  
  # seed: the seed for randomization
  # sim_N: number of simulation
  # ss: sample size in the simulation
  # effect: deviation from null
  # nil_effect: null effect
  
  set.seed(seed)
  
  sim_1 <- data.frame(obs = rbinom(sim_N, size = ss, prob = nil_effect + effect ))
  sim_1$sex <- "male"
  sim_1$iter <- seq(sim_N)
  sim_2 <- data.frame(obs = ss - sim_1$obs)
  sim_2$sex <- "female"
  sim_2$iter <- seq(sim_N)
  
  sim <- sim_1 %>% 
    dplyr::bind_rows(., sim_2) %>% 
    dplyr::arrange(iter)
  
  test_BF <- data.frame(matrix(nrow = sim_N, ncol = 3))
  colnames(test_BF) <- c("Iter", "1st_prop", "BF10")
  
  for (ii in seq(sim_N)){
    test_df <- sim %>%
      dplyr::filter(iter == ii) %>%
      dplyr::mutate(expected = nil_effect * ss)
    
    # test_df1$obs <- c(test_df1$expected[1] - ii, test_df1$expected[2] + ii)
    tmp_BF <- BayesMultiNomial(test_df, factor = 'sex', observed = 'obs', 
                               expected = 'expected', 
                               prior = rep(prior, 2))
    test_BF$Iter[ii] <- ii
    test_BF$`1st_prop`[ii] <- test_df$expected[1] - ii
    # test_BF$`log_BF10`[ii] <- tmp_BF$BF$LogBF10
    test_BF$`BF10`[ii] <- tmp_BF$BF$BF10
    
  }
  
  BF_power <- data.frame(matrix(nrow = 1, ncol = 6))
  colnames(BF_power) <- c("Category", "Prob", "Prior","Sample_Size", "BF_6", "BF_10")
  
  if (effect == 0) {
    BF_power$Prob <- nil_effect + effect
    BF_power$Sample_Size <- ss
    BF_power$Prior <- prior
    BF_power$Category <- "BF01"
    # BF_power$BF_1 <- sum(test_BF$BF10 < 1)/1000 
    BF_power$BF_6 <- sum(test_BF$BF10 <= 1/6)/1000 
    BF_power$BF_10 <- sum(test_BF$BF10 <= 1/10)/1000 
  } else {
    BF_power$Prob <- nil_effect + effect
    BF_power$Category <- "BF10"
    BF_power$Sample_Size <- ss
    BF_power$Prior <- prior
    # BF_power$BF_1 <- sum(test_BF$BF10 > 1)/1000 
    BF_power$BF_6 <- sum(test_BF$BF10 >= 6)/1000 
    BF_power$BF_10 <- sum(test_BF$BF10 >= 10)/1000 
  }
  return(BF_power)
}

### false positive rate
Sim_False_Pos_Binom <- Sim_Power_binormial()
Sim_False_Pos_Binom
```

```{r test default prior with varying N, message=TRUE, warning=FALSE,eval=FALSE}
### simulation for Power
SESOI <- 0.06
Sample_sizes <- seq(100, 1500, 100) # create a sequence from 100 to 2000, with 500 step size.

Sample_sizes <- c(Sample_sizes, 1000)

# iterate each of theses probabilities and save the percentage of BF10 >=3, BF10 >=60
rm(res_bf_binom)  # remove variable with name "res_bf_power_binom" to avoid error
for (jj in (seq(length(Sample_sizes)))){
  tmp_power  <- Sim_Power_binormial(seed = 1000, ss = Sample_sizes[jj], effect = 0.06)
  tmp_falpos <- Sim_Power_binormial(seed = 1000, ss = Sample_sizes[jj], effect = 0)
  if (exists("res_bf_binom")){
    res_bf_binom <- rbind(res_bf_binom, tmp_power,tmp_falpos)
  } else {
    res_bf_binom <- rbind(tmp_power,tmp_falpos)
  }
}

res_bf_binom <- res_bf_binom %>% 
  dplyr::arrange(Category, Sample_Size)

# plot the results
p_sim1 <- res_bf_binom %>%
  ggplot2::ggplot(., aes(x = Sample_Size, y = BF_10, color=Category)) +
  ggplot2::geom_point() + 
  ggplot2::geom_hline(yintercept = 0.8) +
  ggplot2::theme_classic()

ggsave("p_sim2.png", p_sim1, width = 8, height = 5)
```


The above simulation showed that to detected the minimal deviation, 0.06, from 0.5 with non-informative prior, we need a sample size N >= 1200. This sample size is reasonable in this meta-research.

```{r test default prior with varying prior, message=TRUE, warning=FALSE,eval=FALSE}
### simulation for Power
SESOI <- 0.06
priors <- seq(0.1, 1, 0.1) # create a sequence from 100 to 2000, with 500 step size.
priors <- c(priors, c(1, 1.5, 2, 2.5, 3))
# iterate each of theses probabilities and save the percentage of BF10 >=3, BF10 >=60
rm(res_bf_binom_prior)  # remove variable with name "res_bf_power_binom" to avoid error
for (jj in (seq(length(priors)))){
  tmp_power  <- Sim_Power_binormial(seed = 1000, ss = 100, effect = 0.06, prior = priors[jj])
  tmp_falpos <- Sim_Power_binormial(seed = 1000, ss = 100, effect = 0, prior = priors[jj])
  if (exists("res_bf_binom_prior")){
    res_bf_binom_prior <- rbind(res_bf_binom_prior, tmp_power,tmp_falpos)
  } else {
    res_bf_binom_prior <- rbind(tmp_power,tmp_falpos)
  }
}

res_bf_binom_prior <- res_bf_binom_prior %>% 
  dplyr::arrange(Category, Prior)

# plot the results
p_sim2 <- res_bf_binom_prior %>% 
  dplyr::arrange(Category, Prior) %>%
  ggplot2::ggplot(., aes(x = Prior, y = BF_10, color=Category)) +
  ggplot2::geom_point() + 
  ggplot2::geom_hline(yintercept = 0.8) +
  ggplot2::theme_classic()

# save the plot
p_sim <- p_sim1 + p_sim2 +
  plot_layout(guides = 'collect') + plot_annotation(tag_levels = 'A')

ggsave("p_sim.png", p_sim, width = 10, height = 4)
```

The above simulation revealed that varying prior unable to increase the chance of detecting the minimal deviation. Thus, we will not change the prior.

In short, the above simulation showed that our test can detect the smalles effect size of interest with non-informative prior and N >=1200.

#### Test the default prior for age bins

```{r test default prior for age ratio, message=FALSE, warning=FALSE, eval=FALSE}

# Do the simulation with a time-consuming for-loop.
# We keep this code just for clarity
# Not evaluated when running the rmarkdown

Sim_Power_mult_calc <- function(seed = 12345, 
                           sim_N = 50,             # set to 5000 for real simulation
                           sample_N = 1200,
                           sim_prob = c(0.2, 0.2, 0.2, 0.2, 0.2), 
                           nil_effect = c(0.2, 0.2, 0.2, 0.2, 0.2)){
  library(tidyverse)
  
  set.seed(seed)

  tmp_data <- data.frame(rmultinom(n=sim_N, size=sample_N, prob = sim_prob))

  test_BF <- data.frame(matrix(nrow = sim_N, ncol = 2))
  colnames(test_BF) <- c("Iter", "BF10")
  for (ii in seq(sim_N)){
      sim_data1 <- tmp_data[, ii]
      sim_data2 <- nil_effect * sample_N
      test_df <- data.frame(expected = sim_data2,
                            obs = sim_data1)%>%
        dplyr::mutate(ageBins = paste0('bin', seq(5)))
      
      tmp_BF <- BayesMultiNomial(test_df, 
                                 factor = 'ageBins', 
                                 observed = 'obs', 
                                 expected = 'expected')
      test_BF$Iter[ii] <- ii
      test_BF$`BF10`[ii] <- tmp_BF$BF$BF10
      
  }
  
  BF_power <- data.frame(matrix(nrow = 1, ncol = 5))
  colnames(BF_power) <- c("Prob", "Category", "Sample_Size", "BF_6", "BF_10")
  
  BF_power$Prob <- paste0(round(sim_prob, 3), collapse = ';')
  
  if (sum(sim_prob == nil_effect)==length(sim_prob)) {
    
    BF_power$Category <- "Evidence_for_Null"
    BF_power$Sample_Size <- sample_N
    BF_power$BF_6 <- sum(test_BF$BF10 <= 1/6)/sim_N 
    BF_power$BF_10 <- sum(test_BF$BF10 <= 1/ 10)/sim_N 
  } else {
    BF_power$Category <- "Evidence_for_Effect"
    BF_power$Sample_Size <- sample_N
    BF_power$BF_6 <- sum(test_BF$BF10 >= 6)/sim_N 
    BF_power$BF_10 <- sum(test_BF$BF10 >= 10)/sim_N 
  }
  return(BF_power)
}

### false positive rate for this case
Sim_False_Pos_mult <- Sim_Power_mult_calc(sim_N = 50)

Sim_Power_mult <- function(seed = 12345, 
                           sim_N = 1000,        # number of simulations for each multinomial prob vector, default: 1000
                           sim_N_probs = 50,  # number of multinomial prob vectors, default is 5000 
                           sample_N = 1200,
                           sim_alpha = 1){
  set.seed(seed)
  
  sim_probs <- data.frame(gtools::rdirichlet(n = sim_N_probs, alpha = rep(sim_alpha, 5)))
  colnames(sim_probs) <- paste0("bin", seq(5))
  
  # using apply?
  # tmp <- apply(sim_probs, 1, function(x) Sim_Power_mult_calc(sim_prob = x))
  
  rm('res_bf_power_mult')
  for (jj in (seq(nrow(sim_probs)))){ 
    tmp_power <- Sim_Power_mult_calc(sim_prob = sim_probs[jj, 1:5],
                                     sim_N = sim_N,
                                     sample_N = sample_N,
                                     nil_effect = c(0.2, 0.2, 0.2, 0.2, 0.2))
    
    tmp_power$sim_alpha <- sim_alpha
    if (exists("res_bf_power_mult")){
      res_bf_power_mult <- rbind(res_bf_power_mult, tmp_power)
    } else {
      res_bf_power_mult <- tmp_power
    }
  }
  return(res_bf_power_mult)
}

# Test the function "Sim_Power_mult" with 50 times, and alpha for Dirichlet distribution as a vector of 10s
startTime <- Sys.time()
test <- Sim_Power_mult(sim_N = 50, sim_N_probs = 50, sim_alpha = 1)
endTime <- Sys.time()
print(endTime - startTime) # 19 sec

# If the above test is successful, then run the following code, using the default setting of "Sim_Power_mult", i.e., 10000 probabilities for each.

# alpha vector of Dirichlet, and 5000 multinomial vector for each probability, which means 10000 * 5000 iterations, it will take a few hours.

startTime <- Sys.time()
rm('Res_Sim_Multi')
Res_Sim_Multi <- Sim_Power_mult()
endTime <- Sys.time()
print(endTime - startTime) # approximately 9 hourse

# for (sim_alpha in c(1,2,3)){
#   # to quickly test the function, set sim_N = 5, sim_N_probs = 10
#   Sim_res_tmp <-  Sim_Power_mult(sim_N = 5000, 
#                                  sim_N_probs = 10000,
#                                  sim_alpha = sim_alpha)
# 
#   if (exists("Res_Sim_Multi")){
#       Res_Sim_Multi <- rbind(Res_Sim_Multi, Sim_res_tmp)
#     } else {
#       Res_Sim_Multi <- Sim_res_tmp
#     }
#   
# }

Res_Sim_Multi <- Res_Sim_Multi %>%
  dplyr::arrange(sim_alpha, BF_10)

Res_Power <- Res_Sim_Multi %>%
  dplyr::group_by(sim_alpha) %>%
  dplyr::filter(BF_10 >=0.8) %>%
  dplyr::summarise(n = n()/(nrow(Res_Sim_Multi)/length(unique(Res_Sim_Multi$sim_alpha))))
Res_Sim_Multi 
Res_Sim_Multi %>% 
  dplyr::group_by(sim_alpha) %>%
  dplyr::mutate(Iter = seq(n())) %>%
  dplyr::ungroup() %>%
  ggplot2::ggplot(., aes(x = Iter, y = BF_10, group = sim_alpha)) +
  ggplot2::geom_point(aes(color = as.factor(sim_alpha))) + 
  ggplot2::geom_hline(yintercept = 0.8) +
  ggplot2::theme_classic()
```

## Try parallel processing for the simulation: `foreach`
Thanks Mengzheng for writing it in parallel.

```{r define sim fun with foreach, eval=FALSE}
# define a function for the simulation with foreach
Sim_Power_mult_mt <- function(seed = 12345, 
                              sim_N = 50,
                              # number of simulations for each multinomial prob vector, default: 1000
                              sim_N_probs = 50,
                              # number of multinomial prob vectors, default is 5000 
                              sample_N = 1200,
                              sim_alpha = 1){
  
  # Query the total number of threads
  cl <- makeCluster(detectCores())
  registerDoParallel(cl)
  
  # generate probability vectors for multinomial distributions
  sim_probs <- data.frame(gtools::rdirichlet(n = sim_N_probs, alpha = rep(sim_alpha, 5)))
  colnames(sim_probs) <- paste0("bin", seq(5))
  
  # foreach
  res_bf_power_mult <- foreach(jj = seq(nrow(sim_probs)), .combine = rbind) %dopar% {
    
    set.seed(12345 + jj) # seed must be inside foreach
    
    ####################### Function must be defined inside foreach #######################
    BayesMultiNomial <- function(dataset, factor, observed, expected, 
                                 default_prior = TRUE, prior = NA){
        # datase - the input dataframe
        # factor - column name of the factor,
        # observed - column name of the column contains counts information for the observed,
        # expected - column name of the column contains counts information for the expected,
        # default_prior - whether use the default, defused prior
        # prior - priors defined by users
        
        fact_level <- dataset %>% dplyr::select(all_of(factor)) %>% dplyr::pull()
        observed_data <- dataset %>% dplyr::select(all_of(observed)) %>% dplyr::pull()
        names(observed_data) <- fact_level
        expected_data <- dataset %>% dplyr::select(all_of(expected)) %>% dplyr::pull()
        n_levels <- length(observed_data)
        
        if (default_prior & all(is.na(prior))) {
          prior <- rep(1, n_levels)
        } else{
          if (is.character(prior)){
            prior <- dataset %>% dplyr::select(all_of(prior)) %>% dplyr::pull()
          } else if (is.array(prior)){
            prior <-  prior
          } else if (is.numeric(prior)){
            prior <-  prior
          } else{
            print("prior much a column of the input data or a vector")
          }
        }
        
        alphas <- prior
        counts <- observed_data
        thetas <- expected_data
        
        if(sum(thetas) != 1) {
          thetas <- thetas/sum(thetas)
          }
        
        expected <- setNames(sum(counts)*thetas, names(counts))
        
        lbeta.xa <- sum(lgamma(alphas + counts)) - lgamma(sum(alphas + counts))
        lbeta.a  <- sum(lgamma(alphas)) - lgamma(sum(alphas))
      
        if (any(rowSums(cbind(thetas, counts)) == 0)) {
          LogBF10 <- (lbeta.xa-lbeta.a)
        } else {
          LogBF10 <- (lbeta.xa-lbeta.a) + (0 - sum(counts * log(thetas))) 
        }
      
        BF <- data.frame(LogBF10 = LogBF10,
                         BF10    = exp(LogBF10),
                         BF01    = 1/exp(LogBF10))
      
        return(list(BF       = BF,
                    expected = expected))
        
      }
    
    Sim_Power_mult_calc <- function(seed = 12345, 
                                    sim_N = 50,             # set to 5000 for real simulation
                                    sample_N = 1200,
                                    sim_prob = c(0.2, 0.2, 0.2, 0.2, 0.2), 
                                    nil_effect = c(0.2, 0.2, 0.2, 0.2, 0.2)){
      # load library inside the 
      library(tidyverse)
      
      set.seed(seed)
    
      tmp_data <- data.frame(rmultinom(n=sim_N, size=sample_N, prob = sim_prob))
    
      test_BF <- data.frame(matrix(nrow = sim_N, ncol = 2))
      colnames(test_BF) <- c("Iter", "BF10")
      for (ii in seq(sim_N)){
          sim_data1 <- tmp_data[, ii]
          sim_data2 <- nil_effect * sample_N
          test_df <- data.frame(expected = sim_data2,
                                obs = sim_data1)%>%
            dplyr::mutate(ageBins = paste0('bin', seq(5)))
          
          tmp_BF <- BayesMultiNomial(test_df, 
                                     factor = 'ageBins', 
                                     observed = 'obs', 
                                     expected = 'expected')
          test_BF$Iter[ii] <- ii
          test_BF$`BF10`[ii] <- tmp_BF$BF$BF10
          
      }
      
      BF_power <- data.frame(matrix(nrow = 1, ncol = 5))
      colnames(BF_power) <- c("Prob", "Category", "Sample_Size", "BF_6", "BF_10")
      
      BF_power$Prob <- paste0(round(sim_prob, 3), collapse = ';')
      
      if (sum(sim_prob == nil_effect)==length(sim_prob)) {
        
        BF_power$Category <- "Evidence_for_Null"
        BF_power$Sample_Size <- sample_N
        BF_power$BF_6 <- sum(test_BF$BF10 <= 1/6)/sim_N 
        BF_power$BF_10 <- sum(test_BF$BF10 <= 1/ 10)/sim_N 
      } else {
        BF_power$Category <- "Evidence_for_Effect"
        BF_power$Sample_Size <- sample_N
        BF_power$BF_6 <- sum(test_BF$BF10 >= 6)/sim_N 
        BF_power$BF_10 <- sum(test_BF$BF10 >= 10)/sim_N 
      }
      return(BF_power)
    }
    ######################################################################################
    
    tmp_power <- Sim_Power_mult_calc(sim_prob = sim_probs[jj, 1:5],
                                     sim_N = sim_N,
                                     sample_N = sample_N,
                                     nil_effect = c(0.2, 0.2, 0.2, 0.2, 0.2))
    tmp_power$sim_alpha <- sim_alpha
    return(tmp_power)
  }
  
  # close the used thread
  stopCluster(cl)
  
  return(res_bf_power_mult)
}
```

```{r test foreach, eval=FALSE, warning=FALSE}
Sim_Power_mult_mt(seed = 12345, 
                              sim_N = 50,
                              # number of simulations for each multinomial prob vector, default: 1000
                              sim_N_probs = 50,
                              # number of multinomial prob vectors, default is 5000 
                              sample_N = 1200,
                              sim_alpha = 1)
```


```{r test foreach, eval=FALSE, warning=FALSE}
# startTime <- Sys.time()
# test <- Sim_Power_mult(sim_N = 100, sim_N_probs = 100, sim_alpha = 1)
# endTime <- Sys.time()
# print(endTime - startTime) # 1.15 min

# Test the function "Sim_Power_mult" with 50 times, and alpha for Dirichlet distribution as a vector of 10s
startTime <- Sys.time()
test_mt <- Sim_Power_mult_mt(sim_N = 100, sim_N_probs = 100, sim_alpha = 1)
endTime <- Sys.time()
print(endTime - startTime) # 25.7 sec, approximately 1/8 of the original
```

Our simulation found that, for age ratio, the current setting (prior and threshold of BF value as 6), the results revealed that for 93.8% of the probabilities generated by an “uniform” Dirichlet distribution, the current setting can provide evidence that the probability is different from null with in 80% of the case. 

# Load data and preprocess the data

Because Jones et al.(201)' data is needed for the next part (Re-addressing the age bin issue), let's load and preprocess the data first.

```{r Loading data, message=FALSE, warning=FALSE}
load("df_chinese_subj_rr_stage1.RData")
```

```{r disposal data, message=FALSE, warning=FALSE}
df_census6_age <- df_census6 %>% 
  dplyr::select(1,3,4) %>% 
  dplyr::rename(ageBins=1,
                male=2,
                female=3) %>% 
  dplyr::mutate_at(c("ageBins","male","female"),as.numeric) %>% 
  na.omit() %>% 
  dplyr::add_row(ageBins=100,
                 male=8852,
                 female=27082) %>%  ###100 represent 100 years old and above
  tidyr::pivot_longer(-ageBins,names_to = "sex",values_to = "num")
 
df_census7_age <- df_census7 %>% 
  dplyr::select(1,3,4) %>% 
  dplyr::rename(ageBins=1,
                male=2,
                female=3) %>% 
  dplyr::mutate_at(c("ageBins","male","female"),as.numeric) %>% 
  na.omit() %>% 
  dplyr::add_row(ageBins=100,
                 male=35129,
                 female=83737) %>% ###100 represent 100 years old and above
  tidyr::pivot_longer(-ageBins,names_to = "sex",values_to = "num")
  
```

## Re-addressing the age bin issue
This time, we tried to conduct a simulation using the logic as we generate age count data from the mean and SD data extracted from papers.

The simulation will use N as 1200 so that it will reveal the sensitivity of the sample size that resulted from sex ratio data.

```{r sensitivity analysis by mean age, eval=FALSE}
## First, we get a reasonable  mean age range by using PSA 001's data
# get the SD of age from PSA001
df_PSA001_CN_SD <- df_PSA001 %>%
  dplyr::filter(Countries == "CHN") %>%
  dplyr::summarise(SD = sd(Age)) %>%
  dplyr::pull(SD)
df_PSA001_CN_M <- df_PSA001 %>%
  dplyr::filter(Countries == "CHN") %>%
  dplyr::summarise(M = mean(Age)) %>%
  dplyr::pull(M)
Sim_Sens_mult <- function(Mean1, diff_age, SD1, SD2, sampe_N=1200){
  
  # get the mean of difference
  Mean2 <- Mean1 + diff_age
  # Generate data with N = 1200
  # 0~17, 18~25, 26~40, 41~60, 61~
  ageData1 <- round((pnorm(c(18,26,41,61), mean = Mean1, sd =SD1) * sampe_N))
  ageData2 <- round((pnorm(c(18,26,41,61), mean = Mean2, sd =SD2) * sampe_N))
  
    # create a dataframe with ageData1 and ageData2:
  sim_age_df <- setNames(data.frame(matrix(ncol = 3, nrow = 5)), c("ageBins", "sim1", "sim2"))
  sim_age_df$ageBins <- c("<=17", "18~25", "26~40", "41~60", ">=61")
  sim_age_df$sim1[0:4] <- ageData1
  sim_age_df$sim2[0:4] <- ageData2
  
  # create a dataframe with ageData1 and ageData2:
  sim_age_df <- setNames(data.frame(matrix(ncol = 3, nrow = 5)), c("ageBins", "sim1", "sim2"))
  sim_age_df$ageBins <- c("<=17", "18~25", "26~40", "41~60", ">=61")
  sim_age_df$sim1[0:4] <- ageData1
  sim_age_df$sim2[0:4] <- ageData2
  
  sim_age_df <- sim_age_df %>%
    dplyr::mutate(sim1_new = sim1 - lag(sim1),
                  sim1_new = ifelse(is.na(sim1_new), sim1, sim1_new),
                  sim2_new = sim2 - lag(sim2),
                  sim2_new = ifelse(is.na(sim2_new), sim2, sim2_new),
                  # fill NA and zeros with 1 to avoid the error for Bayesian multinomial test
                  sim1_new = ifelse((is.na(sim1_new) | sim1_new == 0), 1, sim1_new),
                  sim2_new = ifelse((is.na(sim2_new) | sim2_new == 0), 1, sim2_new),
                  ageBins = factor(ageBins, levels = c("<=17", "18~25", "26~40", "41~60", ">=61"))) %>%
    dplyr::select(ageBins, sim1_new, sim2_new) %>%
    dplyr::rename(obs = sim1_new,
                  expected = sim2_new)
  
  tmp_BF <- BayesMultiNomial(sim_age_df, 
                              factor = 'ageBins', 
                              observed = 'obs', 
                              expected = 'expected')
  
  # res <- c(tmp_BF$BF$BF10, tmp_BF$LogBF10)
  return(tmp_BF)
}
tmp <- Sim_Sens_mult(Mean1=df_PSA001_CN_M, 
              diff_age=0, 
              SD1=df_PSA001_CN_SD, 
              SD2=df_PSA001_CN_SD, 
              sampe_N=1200)
## record results
sim_age_diff <- seq(0, 2, 0.05)
rm('sim_MNtest')
sim_MNtest <- data.frame(matrix(nrow = 0, ncol = 4))
colnames(sim_MNtest) <- c("MeanAge1","ageDiff","BF10", "LogBF10")
meanAges <- c(10, 15, 20, df_PSA001_CN_M, 25, 30, 35, 40, 45, 50, 55, 60)
for (age in meanAges) {
  
  tmp_sens  <- data.frame(matrix(nrow = length(sim_age_diff), ncol = 4))
  colnames(tmp_sens) <- c("MeanAge1","ageDiff","BF10", "LogBF10")
  tmp_sens$MeanAge1 <- age
  
  for (kk in (seq(length(sim_age_diff)))){
    tmp_BF <- Sim_Sens_mult(Mean1=age, 
                            diff_age=sim_age_diff[kk],
                            SD1=df_PSA001_CN_SD, 
                            SD2=df_PSA001_CN_SD, 
                            sampe_N=1200)
    
    tmp_sens$ageDiff[kk] <- sim_age_diff[kk]
    tmp_sens$BF10[kk] <- tmp_BF$BF$BF10
    tmp_sens$LogBF10[kk] <- tmp_BF$BF$LogBF10
  }
  sim_MNtest <- rbind(sim_MNtest, tmp_sens)
}
p_age_sim1 <- sim_MNtest %>% 
  ggplot2::ggplot(aes(x = ageDiff, y = LogBF10, color = as.factor(MeanAge1))) + 
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = c(log(10), log(1/10))) +
  ggplot2::theme_classic() 
```


Below, we conducted the sensitivity analysis in an alternative way. Note that we only keep the function with `foreach`, i.e., parallel processing. 

```{r sensitivity analysis by mean age alternative, eval=FALSE}
Sim_Sens_mult_alt_par <- function(seed = 125, age_param, SD1, SD2, sampe_N=1200, sim_N=1000){
  # Query the total number of threads
  cl <- makeCluster(detectCores())
  registerDoParallel(cl)
  
  # foreach
  res_sens_mult <- foreach(jj = seq(nrow(age_param)), .combine = rbind) %dopar% {
    
    set.seed(125 + jj) # seed must be inside foreach
    
    #######################Function must be defined inside foreach#######################
    BayesMultiNomial <- function(dataset, factor, observed, expected, 
                                 default_prior = TRUE, prior = NA){
        # datase - the input dataframe
        # factor - column name of the factor,
        # observed - column name of the column contains counts information for the observed,
        # expected - column name of the column contains counts information for the expected,
        # default_prior - whether use the default, defused prior
        # prior - priors defined by users
        
        fact_level <- dataset %>% dplyr::select(all_of(factor)) %>% dplyr::pull()
        observed_data <- dataset %>% dplyr::select(all_of(observed)) %>% dplyr::pull()
        names(observed_data) <- fact_level
        expected_data <- dataset %>% dplyr::select(all_of(expected)) %>% dplyr::pull()
        n_levels <- length(observed_data)
        
        
        if (default_prior & all(is.na(prior))) {
          prior <- rep(1, n_levels)
        } else{
          if (is.character(prior)){
            prior <- dataset %>% dplyr::select(all_of(prior)) %>% dplyr::pull()
          } else if (is.array(prior)){
            prior <-  prior
          } else if (is.numeric(prior)){
            prior <-  prior
          } else{
            print("prior much a column of the input data or a vector")
          }
        }
        
        alphas <- prior
        counts <- observed_data
        thetas <- expected_data
        
        if(sum(thetas) != 1) {
          thetas <- thetas/sum(thetas)
          }
        
        expected <- setNames(sum(counts)*thetas, names(counts))
        
        lbeta.xa <- sum(lgamma(alphas + counts)) - lgamma(sum(alphas + counts))
        lbeta.a  <- sum(lgamma(alphas)) - lgamma(sum(alphas))
      
        if (any(rowSums(cbind(thetas, counts)) == 0)) {
          LogBF10 <- (lbeta.xa-lbeta.a)
        } else {
          LogBF10 <- (lbeta.xa-lbeta.a) + (0 - sum(counts * log(thetas))) 
        }
      
        BF <- data.frame(LogBF10 = LogBF10,
                         BF10    = exp(LogBF10),
                         BF01    = 1/exp(LogBF10))
      
        return(list(BF       = BF,
                    expected = expected))
        
      }
    
    Sim_Sens_mult_alt <- function(Mean1, diff_age, SD1, SD2, sampe_N=1200, sim_N=1000){
      
      pacman::p_load("truncnorm", "tidyverse")
      
      
      # get the mean of difference
      Mean2 <- Mean1 + diff_age
      
      tmp_MNtest_alt <- data.frame(matrix(nrow = 1, ncol = 4))
      colnames(tmp_MNtest_alt) <- c("MeanAge1","ageDiff","Evidence4H1", "Evidence4H0")
    
      count_H10 <- 0
      count_H01 <- 0
      
      for (iter in seq(sim_N)){
        # Generate data with truncated Normal:
        ageData1 <- round(truncnorm::rtruncnorm(n=sampe_N, a=0, b =100, mean = Mean1, sd = SD1))
        ageData2 <- round(truncnorm::rtruncnorm(n=sampe_N, a=0, b =100, mean = Mean2, sd = SD2))
      
        sim_age_df <- data.frame(obs = ageData1, expected=ageData2) %>%
        tidyr::pivot_longer(., cols = obs:expected,
                            names_to = "datasource",
                            values_to = "age") %>%
        dplyr::mutate(ageBins=cut(age,
                                  breaks= c(0, 17.5, 25.5, 40.5, 60.5, 100),
                                  labels= c("<=17", "18~25", "26~40", "41~60", ">=61")),
                      ageBins = factor(ageBins,
                                       levels = c("<=17", "18~25", "26~40", "41~60", ">=61"))) %>%
        dplyr::count(datasource, ageBins) %>%
        tidyr::complete(datasource, ageBins, 
                        fill = list(n=1)) %>% # fill zero with ones
        tidyr::pivot_wider(names_from = datasource,
                           values_from = n)
        
        tmp_BF <- BayesMultiNomial(sim_age_df, 
                                  factor = 'ageBins', 
                                  observed = 'obs', 
                                  expected = 'expected')
        
        if (tmp_BF$BF$BF10 >=10){
          count_H10 <- count_H10 + 1
        } else if (tmp_BF$BF$BF01 >=10){
          count_H01 <- count_H01 + 1
        }
        
        }
  
      tmp_MNtest_alt$MeanAge1[1] <- Mean1
      tmp_MNtest_alt$ageDiff[1] <- diff_age
      tmp_MNtest_alt$Evidence4H1[1] <- count_H10/sim_N
      tmp_MNtest_alt$Evidence4H0[1] <- count_H01/sim_N
      
      return(tmp_MNtest_alt)
      }
    ######################################################################################
    
    tmp_power <- Sim_Sens_mult_alt(Mean1 = age_param$MeanAge1[jj], 
                                   diff_age = age_param$age_diff[jj], 
                                   SD1 = SD1, 
                                   SD2= SD2, 
                                   sampe_N=1200, 
                                   sim_N=1000)
    
    return(tmp_power)
  }
  
  # close the used thread
  stopCluster(cl)
  
  return(res_sens_mult)
}

meanAges <- c(10, 15, 20, df_PSA001_CN_M, 25, 30, 35, 40, 45, 50, 55, 60)
sim_age_diff <- seq(0, 2, 0.05)
sim_age_param <- expand.grid(MeanAge1 = c(10, 15, 20, df_PSA001_CN_M, 25, 30, 35, 40, 45, 50, 55, 60),
                             age_diff = seq(0, 2, 0.05))

# Test the same function with parallel:
startTime <- Sys.time()
test_mt <- Sim_Sens_mult_alt_par(seed = 125, 
                                 age_param = sim_age_param[1:4,], 
                                 SD1=df_PSA001_CN_SD, 
                                 SD2=df_PSA001_CN_SD, 
                                 sampe_N=1200, sim_N=1000)
endTime <- Sys.time()
print(endTime - startTime) # 19 sec, approximately 1/8 of the original

### run the above simulation with parallel will need 39 minutes
rm('sim_MNtest_alt')
startTime <- Sys.time()
sim_MNtest_alt <- Sim_Sens_mult_alt_par(seed = 125, 
                                 age_param = sim_age_param, 
                                 SD1=df_PSA001_CN_SD, 
                                 SD2=df_PSA001_CN_SD, 
                                 sampe_N=1200, sim_N=1000)
endTime <- Sys.time()
print(endTime - startTime) # 28.55047 mins for Mac book pro with M1 chip

# rate of correct rejection
sim_MNtest_alt_cr <- sim_MNtest_alt %>%
  dplyr::filter(ageDiff == 0) %>%
  dplyr::arrange(Evidence4H0)

# data for sensitivity
sim_MNtest_alt_pw <- sim_MNtest_alt %>%
  dplyr::filter(ageDiff != 0)

# select only with 80% power to check data
sim_MNtest_alt_pw80 <- sim_MNtest_alt %>%
  dplyr::filter(ageDiff != 0 & Evidence4H1 >= 0.8) %>%
  dplyr::arrange(MeanAge1, ageDiff) %>%
  dplyr::group_by(MeanAge1) %>%
  dplyr::filter(row_number() ==1) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(ageDiff)

# plot the alternative results
p_age_sim2 <- sim_MNtest_alt_pw %>% 
  ggplot2::ggplot(aes(x = ageDiff, y = Evidence4H1, color = as.factor(MeanAge1))) + 
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0.8) +
  ggplot2::theme_classic()
```

```{r}
p_age_sim <- p_age_sim1 + p_age_sim2
p_age_sim
ggsave("p_age_sim.png", p_age_sim, width = 10, height = 4)
```




## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
