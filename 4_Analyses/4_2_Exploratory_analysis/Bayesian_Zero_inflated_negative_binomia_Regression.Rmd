---
title: "Bayesian_Zero_inflated_negative_binomia_Regression"
author: "liu_weibiao"
output: html_document
date: "2024-10-02"
---

```{r}
library(tidyverse)        # ggplot, dplyr, %>%, and friends
library(brms)             # Bayesian modeling through Stan
library(rstan)             # Bayesian modeling through Stan
library(marginaleffects)  # Calculate marginal effects for regression models
library(tidybayes)        # Manipulate Stan objects in a tidy way
library(patchwork)        # Combine ggplot objects
library(ggrepel)          # Automatically position labels
library(scales)           # Format numbers in nice ways
library(collapse) 
library(broom)            # Convert model objects to data frames
library(broom.mixed)      # Convert brms model objects to data frames
library(extraDistr)       # Use extra distributions like dprop()
library(ggdist)           # Special geoms for posterior distributions
library(gghalves)         # Special half geoms
library(ggbeeswarm)       # Special distribution-shaped point jittering
library(modelsummary)     # Create side-by-side regression tables
library(ggthemes)
library(wesanderson)
library(gridExtra)        # Merge Graphs
library(bayesplot)
```


### Country-level
Country-level relationship between proportion of sample and socioeconomic/cultural factors for traditional studies (using PS2014 as an example) and big team science (using PSA 001 as an example)

### Taking GDP per capita as an example
# 1 View data
```{r}
gdpdata <- read_csv("gdpdata.csv")%>%
  mutate(log_GDP_per_capita = log(GDP_per_capita))%>% #Log Transformations
  mutate(log_bts_sample_size = log(bts_sample_size))  %>% #Log Transformations
  mutate(log_ps_sample_size = log(ps))   #Log Transformations
gdpdata

#Observe the distribution of independent variables 
ggplot(gdpdata, aes(x = GDP_per_capita)) +
  geom_density() +
  labs(title = "Density Plot of GDP per capita", x = "GDP per capita", y = "Density") +
    theme_bw() +
  theme_minimal()+
  theme(
    text = element_text(size = 22),
    plot.title = element_text(hjust = .5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    strip.background =element_blank(),
    axis.line.x.bottom = element_line(color = 'black'),
    axis.line.y.left   = element_line(color = 'black'),
    legend.position = "none")
#Normality test
shapiro.test(gdpdata$GDP_per_capita)
```
By examining the distribution map and the normality test, it can be seen that the distribution of the independent variables is not normal.Therefore, Therefore, we performed logarithmic transformation on the data of GDP per capita.

The data distribution of GDP per capita after logarithmic transformation is as follows
```{r}
#Observe the distribution of independent variables 
ggplot(gdpdata, aes(x = log_GDP_per_capita)) +
  geom_density() +
  labs(title = "Density Plot of GDP per capita", x = "log_GDP_per_capita", y = "Density") +
    theme_bw() +
  theme_minimal()+
  theme(
    text = element_text(size = 22),
    plot.title = element_text(hjust = .5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    strip.background =element_blank(),
    axis.line.x.bottom = element_line(color = 'black'),
    axis.line.y.left   = element_line(color = 'black'),
    legend.position = "none")
shapiro.test(gdpdata$log_GDP_per_capita)
```

The sample size is the dependent variable, which is a simple count data that contains many zeros, and non-zero data has over-dispersion. To diagnose overdispersion of count data, we used the model comparison leaf one out cross validation (LOO-CV) method to compare the zero-inflation Poisson model with the zero-inflation negative binomial regression [Winter & Bürkner, 2021](https://doi.org/10.1111/lnc3.12439).
```{r}
gdp_zero_inflated_poisson_bts <- brms::brm(
   bf(bts_sample_size ~ 1 + log_GDP_per_capita,
      zi ~ 1 + log_GDP_per_capita ),
  data = gdpdata,
  family = zero_inflated_poisson(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,
  
  save_pars = save_pars(all = TRUE),  
  control = list(adapt_delta = 0.99,  max_treedepth=10), 
  backend = "cmdstanr",
  file = "gdp_zero_inflated_poisson_bts"
)
gdp_zero_inflated_poisson_bts
```

```{r}
gdp_zero_inflated_negbinomial_bts <- brms::brm(
   bf(bts_sample_size ~ 1 + log_GDP_per_capita,
      zi ~ 1 + log_GDP_per_capita ),
  data = gdpdata,
  family = zero_inflated_negbinomial(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,

  save_pars = save_pars(all = TRUE),  
  control = list(adapt_delta = 0.99,  max_treedepth=10), 
  backend = "cmdstanr",
  file = "gdp_zero_inflated_negbinomial_bts"
)
gdp_zero_inflated_negbinomial_bts
```

```{r}
loo_poisson <- loo(gdp_zero_inflated_poisson_bts, moment_match = TRUE)
loo_negbinomial <- loo(gdp_zero_inflated_negbinomial_bts, moment_match = TRUE)
loo <-  brms::loo_compare(loo_poisson, loo_negbinomial)
loo
```

The results show that the zero inflation Poisson model fits worse (elpd-diff = -5872.8, se-diff = 3133.1), indicating that the data are overdispersion. Therefore, Bayesian zero-inflated negative binomial regression is appropriate to process the data.

# 2 Regression model 
Due to the fact that the dependent variable is simply counted data, contains many zeros and has excessive dispersion, we will use zero-inflated negative binomial regression to fit the data.

## 2.1 Zero-inflated negative binomial regression
### The formula of zero-inflated negative binomial regression 
\begin{array}{r}
$$y_{i} \sim \operatorname{ZINB}\left(\mu_{i}, \quad \phi, \quad p_{i}\right)$$ 
$$\log \left(\mu_{i}\right)=\beta_{0}+\beta_{1} \times x_{i}$$
$$\text{Logit}(p_i) = \gamma_0 + \gamma_1 x_i$$

### The formula of zero-inflated negative binomial distribution 
$$P(Y = y) = 
\begin{cases} 
p + (1 - p) \left(1 + \frac{\mu}{\phi}\right)^{-\phi}, & y = 0 \\ 
(1 - p) \frac{\Gamma(y + \phi)}{y! \Gamma(\phi)} \left(1 + \frac{\mu}{\phi}\right)^{-\phi} \left(1 + \frac{\phi}{\mu}\right)^{-y}, & y = 1, 2, \ldots 
\end{cases}$$

μi is the model predicted value corresponding to xi; μ is the mean of the negative binomial regression part.
ϕ is the shape parameter of the negative binomial regression part.
pi is the predicted probability of 0 for yi corresponding to xi; p is the probability of zero expansion.
# 3 Set priors
### View default priors
```{r}
priors_main <- get_prior(
bf(bts_sample_size ~ log_GDP_per_capita,
zi ~ log_GDP_per_capita),
  data = gdpdata,
  family = zero_inflated_negbinomial(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,
  
  backend = "cmdstanr")
priors_main
```

## 3.1 Set the prior of shape(ϕ)
For the shape parameters in Bayesian negative binomial regression, an inv_gamma(0.4, 0.3) prior is appropriate, as it can cover a broader range (Bürkner, 2024; https://github.com/paul-buerkner/brms/issues/1614). Therefore, we will also use an inv_gamma (0.4, 0.3) prior for the shape parameters in our Bayesian zero-inflated negative binomial regression model.

## 3.2 Set the prior of β0
Based on the self-compiled big team science data, the total sample size, after filtering according to our operational definition, ranges from 1,100,000 to 1,200,000. To ensure that the intercept β₀ can cover all possible ranges from 1 to 1,200,000, we consider two priors: a more diffuse prior, β₀ ~ Normal (0, 4.67), and a more concentrated prior, β₀ ~ Normal (6, 2.67).

Using the properties of the log-normal distribution, the β₀ ~ Normal (0, 4.67) prior covers a range from about 8.23e-07 (e^(0-4.67×3)) to 1,214,691 (e^(0+4.67×3)), while the β₀ ~ Normal (6, 2.67) prior ranges from about 0.13 (e^(6-2.67×3)) to 1,214,691 (e^(6+2.67×3)). Both priors effectively cover the target range of 1 to 1,200,000.

We have made a visual comparison between the intercept priors β₀ ~ Normal (6, 2.67) and β₀ ~ Normal (0, 4.67) (see figure below). 

```{r}
pp1 <- tibble(x       = c(200, 400),
       y       = c(0.00082, 0.00054),
       meanlog = c(0, 6),
       sdlog   = c(4.67, 2.67)) %>% 
  expand_grid(number = seq(from = 0, to = 1190000, length.out = 300000)) %>% 
  mutate(density = dlnorm(number, meanlog, sdlog),
         group   = str_c("alpha%~%Normal(", meanlog, ", ", sdlog, ")")) %>% 
  
  ggplot(aes(fill = group, color = group)) +
  geom_area(aes(x = number, y = density),
            alpha = 3/4, linewidth = 0, position = "identity") +
  geom_text(data = . %>% group_by(group) %>% slice(1),
            aes(x = x, y = y, label = group),
            family = "Times", parse = T,  hjust = 0) +
  scale_fill_manual(values = wesanderson::wes_palette("Moonrise2")[1:2]) +
  scale_color_manual(values = wesanderson::wes_palette("Moonrise2")[1:2]) +
  scale_y_continuous(NULL, breaks = NULL)+
  ylim(0, 0.0013) +
  xlab("Sample size of big team size") +
  theme(
    legend.position = "none",
    panel.grid.major = element_blank(),   
    panel.grid.minor = element_blank(),  
    panel.border = element_blank(),       
    panel.background = element_blank(),  
    axis.line.x = element_line(color = "black"), 
    axis.line.y = element_line(color = "black") 
  )
pp1
ggsave(filename = "pp1.pdf", plot = pp1, device = "pdf", width = 4, height = 4)
```

```{r}
pp2 <- tibble(x       = c(200, 400),
       y       = c(0.00082, 0.00054),
       meanlog = c(0, 6),
       sdlog   = c(4.67, 2.67)) %>% 
  expand_grid(number = seq(from = 0, to = 5000, length.out = 30000)) %>% 
  mutate(density = dlnorm(number, meanlog, sdlog),
         group   = str_c("alpha%~%Normal(", meanlog, ", ", sdlog, ")")) %>% 
  
  ggplot(aes(fill = group, color = group)) +
  geom_area(aes(x = number, y = density),
            alpha = 3/4, linewidth = 0, position = "identity") +
  geom_text(data = . %>% group_by(group) %>% slice(1),
            aes(x = x, y = y, label = group),
            family = "Times", parse = T,  hjust = 0) +
  scale_fill_manual(values = wesanderson::wes_palette("Moonrise2")[1:2]) +
  scale_color_manual(values = wesanderson::wes_palette("Moonrise2")[1:2]) +
  scale_y_continuous(NULL, breaks = NULL)+
  ylim(0, 0.0013) +
  xlab("Sample size of big team size") +
theme(
    legend.position = "none",
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank(),  
    panel.border = element_blank(),      
    panel.background = element_blank(),   
    axis.line.x = element_line(color = "black"), 
    axis.line.y = element_line(color = "black")  
  )
pp2
ggsave(filename = "pp2.pdf", plot = pp2, device = "pdf", width = 4, height = 4)
```
Notably, the prior β₀ ~ Normal (0, 4.67) is more extreme, with a median of e⁰ = 1, whereas the median for β₀ ~ Normal (6, 2.67) is e⁶ = 403.

Given that one big team science study sampled from 187 countries, and that there are approximately 230 countries and regions worldwide, it is reasonable to conclude that most big team science studies sampled from a majority of countries worldwide. However, as the majority of BTS studies sampled from only a few dozen countries, the median sample size per country is likely to represent those countries that are less frequently included in big team science studies. For this median, sample sizes in the range of a few hundred are appropriate. Therefore, β₀ ~ Normal (6, 2.67) is the more appropriate prior.

## 3.3 The intercept γ0 of p_i
The probability of 0 in our data may be mostly concentrated between 0.1-0.9, and after logit transformation it is (-2.2, 2.2). We set γ0~Normal (0,1), which corresponds exactly to this range.

## 3.4 The slope β1 of μ_i  and the slope γ1 of p_i
For the slope parameters β1 and γ1, we use the changing slope to plot the prior prediction distribution and then select the appropriate prior. 

```{r}
set.seed(11)

generate_data_and_plot <- function(sd, title) {
  tibble(i = 1:100,
         a = rnorm(100, mean = 6, sd = 2.7)) %>%
    mutate(
      `beta[1]%~%Normal(0*', '*0.01)` = rnorm(100, mean = 0, sd = 0.01),
      `beta[1]%~%Normal(0*', '*0.05)` = rnorm(100, mean = 0, sd = 0.05),
      `beta[1]%~%Normal(0*', '*0.1)` = rnorm(100, mean = 0, sd = 0.1),
      `beta[1]%~%Normal(0*', '*1)` = rnorm(100, mean = 0, sd = 1),
      `beta[1]%~%Normal(0*', '*10)` = rnorm(100, mean = 0, sd = 10)) %>%
    pivot_longer(contains("beta"), values_to = "b", names_to = "prior") %>%
    expand_grid(x = seq(from = -1, to = 5, length.out = 100)) %>%
    mutate(lambda = exp(1 + a + b * x),
           pi = plogis(1 + rnorm(1, mean = 0, sd = 1) + rnorm(1, mean = 0, sd = sd) * x)) %>%
    rowwise() %>%
    mutate(shape_param = 1 / rgamma(1, shape = 0.4, rate = 0.3),
           y_nb = rnbinom(1, size = shape_param, mu = lambda),
           zero_inflated = rbinom(1, size = 1, prob = pi),
           y = ifelse(zero_inflated == 1, 0, y_nb)) %>%
    ggplot(aes(x = x, y = y, group = i)) +
    geom_line(linewidth = 1/4, alpha = 2/3, color = wes_palette("Moonrise2")[4]) +
    labs(x = "GDP_per_capita", y = "sample size", title = title) +
    coord_cartesian(ylim = c(0, 1200000)) +
    facet_wrap(~ prior, labeller = label_parsed)
}


pp1 <- generate_data_and_plot(0.01, expression(paste(gamma[1] %~% Normal(0*', '*0.01))))+theme(
    legend.position = "none",
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank(),   
    panel.border = element_blank(),       
    panel.background = element_blank(),   
    axis.line.x = element_line(color = "black"), 
    axis.line.y = element_line(color = "black") 
  )
pp2 <- generate_data_and_plot(0.05, expression(paste(gamma[1] %~% Normal(0*', '*0.05))))+theme(
    legend.position = "none",
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank(), 
    panel.border = element_blank(),      
    panel.background = element_blank(),  
    axis.line.x = element_line(color = "black"),
    axis.line.y = element_line(color = "black")  
  )
pp3 <- generate_data_and_plot(0.1, expression(paste(gamma[1] %~% Normal(0*', '*0.1))))+theme(
    legend.position = "none",
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank(),   
    panel.border = element_blank(),       
    panel.background = element_blank(),  
    axis.line.x = element_line(color = "black"), 
    axis.line.y = element_line(color = "black")  
  )
pp4 <- generate_data_and_plot(1, expression(paste(gamma[1] %~% Normal(0*', '*1))))+theme(
    legend.position = "none",
    panel.grid.major = element_blank(),   
    panel.grid.minor = element_blank(),   
    panel.border = element_blank(),       
    panel.background = element_blank(),   
    axis.line.x = element_line(color = "black"), 
    axis.line.y = element_line(color = "black") 
  )

pp <- gridExtra::grid.arrange(pp1, pp2, pp3, pp4, ncol = 1)


ggsave(filename = "ppp.pdf", plot = pp, device = "pdf", width = 8, height = 18)
```
The prior selection can meet two criteria (as shown below): (1) it is within the possible range of values (there are values on the x-axis, and the sample size can take the larger value of 1,200,000); (2) the change in the data is not extreme.

Based on the above criteria, the priors we finally chose were β1 ~ Normal (0, 0.1) & γ1 ~ Normal (0, 0.1).

```{r}
set.seed(11)

generate_data_and_plot <- function(sd, title) {
  tibble(i = 1:100,
         a = rnorm(100, mean = 6, sd = 2.7)) %>%
    mutate( `beta[1]%~%Normal(0*', '*0.1)` = rnorm(100, mean = 0, sd = 0.1)) %>%
    pivot_longer(contains("beta"), values_to = "b", names_to = "prior") %>%
    expand_grid(x = seq(from = -1, to = 5, length.out = 100)) %>%
    mutate(lambda = exp(1 + a + b * x),
           pi = plogis(1 + rnorm(1, mean = 0, sd = 1) + rnorm(1, mean = 0, sd = sd) * x)) %>%
    rowwise() %>%
    mutate(shape_param = 1 / rgamma(1, shape = 0.4, rate = 0.3),
           y_nb = rnbinom(1, size = shape_param, mu = lambda),
           zero_inflated = rbinom(1, size = 1, prob = pi),
           y = ifelse(zero_inflated == 1, 0, y_nb)) %>%
    ggplot(aes(x = x, y = y, group = i)) +
    geom_line(linewidth = 1/4, alpha = 2/3, color = wes_palette("Moonrise2")[4]) +
    labs(x = "GDP_per_capita", y = "sample size", title = title) +
    coord_cartesian(ylim = c(0, 1200000)) +
    facet_wrap(~ prior, labeller = label_parsed)
}


pp1 <- generate_data_and_plot(0.1, expression(paste(gamma[1] %~% Normal(0*', '*0.1))))+theme(
    legend.position = "none",
    panel.grid.major = element_blank(),   
    panel.grid.minor = element_blank(),  
    panel.border = element_blank(),      
    panel.background = element_blank(),   
    axis.line.x = element_line(color = "black"), 
    axis.line.y = element_line(color = "black")  
  )

pp1

ggsave(filename = "pp.pdf", plot = pp1, device = "pdf", width = 6, height = 6)
```

### In summary, the priors we use are as follows:
```{r}
prior = set_prior("normal(0, 0.1 )", class = "b") +
        set_prior("normal(6, 2.67)", class = "Intercept")+
        set_prior("inv_gamma(0.4, 0.3)", class = "shape")+ 
        set_prior("normal(0, 0.1)", class = "b", dpar= "zi") +
        set_prior("normal(0, 1)", class = "Intercept", dpar= "zi")
```

# 4 Prior prediction check
The visualization of the prior prediction check is shown below. 
```{r}
gdp_zero_inflated_negbinomial_bts1 <- brms::brm(
   bf(bts_sample_size ~ 1 + log_GDP_per_capita,
      zi ~ 1 + log_GDP_per_capita),
  data = gdpdata,
  family = zero_inflated_negbinomial(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,
  prior = set_prior("normal(0, 0.1 )", class = "b") +
        set_prior("normal(6, 2.67)", class = "Intercept")+
        set_prior("inv_gamma(0.4, 0.3)", class = "shape")+ 
        set_prior("normal(0, 0.1)", class = "b", dpar= "zi") +
        set_prior("normal(0, 1)", class = "Intercept", dpar= "zi"),
  save_pars = save_pars(all = TRUE),  
  control = list(adapt_delta = 0.99,  max_treedepth=10), 
  sample_prior = "only"
)
```

```{r}
color_scheme_set("brightblue")
pp_check(gdp_zero_inflated_negbinomial_bts1,ndraws=2000)+
  theme_bw() +
  xlim(0, 1240000) +
  ylim(0, 0.0052) +
  #labs(title = "sample") +
  theme(
    text = element_text(size = 22),
    plot.title = element_text(hjust = .5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    strip.background =element_blank(),
    axis.line.x.bottom = element_line(color = 'black'),
    axis.line.y.left   = element_line(color = 'black'),
    legend.position = "none")

pp_check(gdp_zero_inflated_negbinomial_bts1,ndraws=200)+
  theme_bw() +
  xlim(0, 5300) +
  ylim(0, 0.0052) +
  #labs(title = "sample") +
  theme(
    text = element_text(size = 22),
    plot.title = element_text(hjust = .5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    strip.background =element_blank(),
    axis.line.x.bottom = element_line(color = 'black'),
    axis.line.y.left   = element_line(color = 'black'),
    legend.position = "none")

```
The visualization of the prior prediction check is shown below. In the left panel we can see that the sample size can accommodate values up to 1,200,000. As shown in the right-hand panel, the actual data are well encompassed by the prior distribution, indicating that the prior is appropriate.

# 5 Fit model
```{r}
gdp_zero_inflated_negbinomial_bts0 <- brms::brm(
   bf(bts_sample_size ~ 1,
      zi ~ 1),
  data = gdpdata,
  family = zero_inflated_negbinomial(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,
  prior =  
  set_prior("normal(6, 2.67)", class = "Intercept")+
  set_prior("inv_gamma(0.4, 0.3)", class = "shape")+ 
  set_prior("normal(0, 1)", class = "Intercept", dpar= "zi"),
  
  save_pars = save_pars(all = TRUE),  
  control = list(adapt_delta = 0.99,  max_treedepth=10), 
  backend = "cmdstanr",
  file = "gdp_zero_inflated_negbinomial_bts0"
)
gdp_zero_inflated_negbinomial_bts0
```

```{r}
gdp_zero_inflated_negbinomial_bts1 <- brms::brm(
   bf(bts_sample_size ~ 1 + log_GDP_per_capita,
      zi ~ 1 ),
  data = gdpdata,
  family = zero_inflated_negbinomial(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,
  prior =  set_prior("normal(0, 0.1 )", class = "b") +
  set_prior("normal(6, 2.67)", class = "Intercept")+
  set_prior("inv_gamma(0.4, 0.3)", class = "shape")+ 
  set_prior("normal(0, 1)", class = "Intercept", dpar= "zi"),
  
  save_pars = save_pars(all = TRUE),  
  control = list(adapt_delta = 0.99,  max_treedepth=10), 
  backend = "cmdstanr",
  file = "gdp_zero_inflated_negbinomial_bts1"
)
gdp_zero_inflated_negbinomial_bts1
```

```{r}
gdp_zero_inflated_negbinomial_bts2 <- brms::brm(
   bf(bts_sample_size ~ 1 + log_GDP_per_capita,
      zi ~ 1 + log_GDP_per_capita),
  data = gdpdata,
  family = zero_inflated_negbinomial(),
  chains = 4, iter = 20000, warmup = 10000,
  cores = 4, seed = 1234,
 prior = set_prior("normal(0, 0.1 )", class = "b") +
         set_prior("normal(6, 2.67 )", class = "Intercept")+
        set_prior("inv_gamma(0.4, 0.3)", class = "shape")+ 
        set_prior("normal(0, 0.1)", class = "b", dpar= "zi") +
        set_prior("normal(0, 1)", class = "Intercept", dpar= "zi"),
  save_pars = save_pars(all = TRUE),  
  control = list(adapt_delta = 0.99,  max_treedepth=10), 
  backend = "cmdstanr",
  file = "gdp_zero_inflated_negbinomial_bts2"
)
gdp_zero_inflated_negbinomial_bts2

```

```{r}
# Extract the highest density interval (HDI)
library(bayestestR)

# Extract posterior samples
posterior_samples <- as.data.frame(gdp_zero_inflated_negbinomial_bts2)

# Extract median
posterior_medians <- apply(posterior_samples, 2, median)

# Extract HDI
hdi_values <- hdi(posterior_samples, ci = 0.95)

# Integration results
result_df <- data.frame(
  Parameter = names(posterior_medians),
  Median = posterior_medians,
  HDI_Lower = hdi_values$CI_low,
  HDI_Upper = hdi_values$CI_high
)


result_df

posterior_interval(gdp_zero_inflated_negbinomial_bts2, prob = 0.95)
bayestestR::hdi(gdp_zero_inflated_negbinomial_bts2, component = c("all"),ci = 0.95)
bayestestR::ci(gdp_zero_inflated_negbinomial_bts2, component = c("all"),ci = 0.95)
```
### Interpreting results
(1)Intercept=5.43 means that when log (GDP per capita)=0, i.e. GDP per capita=1 ($1000), the model predicts a sample size of exp (5.15)=95.58.

(2)log_GDP_per_capita=0.34 means that when GDP per capital increases by 1%, the model's predicted sample size increases by 0.34%.

(3)Zi_intercept=1.38 means that when log (GDP per capita)=0, i.e. GDP per capita=1 ($1000), the probability of the model predicting a sample size of 0 is plogis (1.38)=79.90%.

(4)Zi_log_GDP_per_capita=-0.09 means that when GDP per capita increases by 1%, the probability of the model predicting a sample size of 0 decreases by 0.08%.

(5)Shape=1.33 indicates excessive dispersion of the sample size data. Based on the variance formula below, the closer the shape parameter is to positive infinity, the smaller the data dispersion, and the closer the shape parameter is to 0, the larger the data dispersion.

$$Var(Y\mid \mu ,\phi )= \mu +\frac{\mu ^{2} }{\phi } $$


# 6 Posterior prediction check
First, as shown in panel (a) below, the actual data are well contained within the posterior predictive distribution. In addition, panels (b) and (c) show that the minimum and mean values of the actual data are close to the center of the posterior predictive distribution. In panel (d), although the maximum value of 2,682 is an outlier (as all other values are below 1,000) and does not fall exactly in the center of the posterior predictive distribution, the distribution adequately covers this extreme value and is therefore acceptable. Overall, this indicates that our model effectively describes the actual data.
```{r}
pp_check(gdp_zero_inflated_negbinomial_bts2, ndraws = 200)+
  xlim(0, 5300) +
  ylim(0, 0.0053) +
theme(
    text = element_text(size = 22),
    plot.title = element_text(hjust = .5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    strip.background =element_blank(),
    axis.line.x.bottom = element_line(color = 'black'),
    axis.line.y.left   = element_line(color = 'black'),
    legend.position = "none")

 # Extract posterior prediction samples from the fitting model
posterior_preds <- posterior_predict(gdp_zero_inflated_negbinomial_bts2, ndraws = 1000)

y = gdpdata$bts_sample_size
#posterior_preds <- t(posterior_preds)
y_df <- as.data.frame(y)

posterior_preds_df <- as.data.frame(posterior_preds)

 ppc_stat(gdp_zero_inflated_negbinomial_bts2,y = y, yrep = posterior_preds,
 stat = "mean")
 ppc_stat(gdp_zero_inflated_negbinomial_bts2,y = y, yrep = posterior_preds,
 stat = "min") 
 ppc_stat(gdp_zero_inflated_negbinomial_bts2,y = y, yrep = posterior_preds,
 stat = "max") 
```

# Country level drawing
## GDP_per_capita drawing
```{r}
gdpdata$log_ps_sample_size[is.infinite(gdpdata$log_ps_sample_size)] <- NA
gdpdata$log_bts_sample_size[is.infinite(gdpdata$log_bts_sample_size)] <- NA

combined_data2 <- rbind(
  transform(gdpdata, source = "PS2014", value = log_ps_sample_size),
  transform(gdpdata, source = "PSA001", value = log_bts_sample_size)
)

gdp1 <- ggplot(combined_data2, aes(x = log_GDP_per_capita, y = value, color = source, fill = source)) +
  
  geom_point(size = 6, alpha = 0.6) +
  geom_smooth(method = "lm",size = 2, alpha = 0.15) +
  
  scale_color_manual(name = "Data source", 
                     values = c("#377EB8", "#E41A1C"), 
                     labels = c("Traditional studies", "Big team science")) +
  scale_fill_manual(name = "Data source", 
                    values = c("#377EB8", "#E41A1C"), 
                    labels = c("Traditional studies", "Big team science")) +
  geom_text_repel(data = combined_data2, aes(label = country_2), max.overlaps=2,label.padding=5,
                   family = "sans", size = 6,
                  nudge_y = 0.2,  # Adjust the position of the label on the y-axis
                  nudge_x = 0.2,
                show.legend = FALSE) + 
  ylab("Log(sample size)") +
  xlab("Log(GDP per capita)") +
  theme(axis.text = element_text(size = 20),
        axis.title = element_text(size = 24),
        panel.background = element_rect(fill = "white"),
        axis.line = element_line(color = "black"),
        aspect.ratio = 1,
        legend.position = "right",  
        legend.text = element_text(size = 18),  
        legend.title = element_text(size = 20)) +
  xlim(c(0, 5)) +
  guides(color = guide_legend(override.aes = list(linetype = c("solid", "dashed"))))

gdp1
# Save for PDF
#ggsave(filename = "GDP.pdf", plot = gdp1, device = "pdf", width = 12, height = 12)


```

